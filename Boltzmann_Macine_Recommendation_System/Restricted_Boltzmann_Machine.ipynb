{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a00cf16-734a-4848-b493-c72b76bdc1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we gonna build 2 Models\n",
    "\n",
    "# First for User like the product or not (\"Yes\" or \"No\")\n",
    "# Second for Find review or rating for the product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce0bd4e-6a13-4957-9be9-5832104e7246",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55488c2-845a-486e-8b00-58e9af8913f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c877e1-6458-416d-8947-cbfa8143e3c0",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fdee4a6-f46b-4e79-9a79-5b0083980682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0                                   1                             2\n",
      "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4        5  Father of the Bride Part II (1995)                        Comedy\n",
      "...    ...                                 ...                           ...\n",
      "3878  3948             Meet the Parents (2000)                        Comedy\n",
      "3879  3949          Requiem for a Dream (2000)                         Drama\n",
      "3880  3950                    Tigerland (2000)                         Drama\n",
      "3881  3951             Two Family House (2000)                         Drama\n",
      "3882  3952               Contender, The (2000)                Drama|Thriller\n",
      "\n",
      "[3883 rows x 3 columns]          0  1   2   3      4\n",
      "0        1  F   1  10  48067\n",
      "1        2  M  56  16  70072\n",
      "2        3  M  25  15  55117\n",
      "3        4  M  45   7  02460\n",
      "4        5  M  25  20  55455\n",
      "...    ... ..  ..  ..    ...\n",
      "6035  6036  F  25  15  32603\n",
      "6036  6037  F  45   1  76006\n",
      "6037  6038  F  56   1  14706\n",
      "6038  6039  F  45   0  01060\n",
      "6039  6040  M  25   6  11106\n",
      "\n",
      "[6040 rows x 5 columns]             0     1  2          3\n",
      "0           1  1193  5  978300760\n",
      "1           1   661  3  978302109\n",
      "2           1   914  3  978301968\n",
      "3           1  3408  4  978300275\n",
      "4           1  2355  5  978824291\n",
      "...       ...   ... ..        ...\n",
      "1000204  6040  1091  1  956716541\n",
      "1000205  6040  1094  5  956704887\n",
      "1000206  6040   562  5  956704746\n",
      "1000207  6040  1096  4  956715648\n",
      "1000208  6040  1097  4  956715569\n",
      "\n",
      "[1000209 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding= 'latin-1')\n",
    "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding= 'latin-1')\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding= 'latin-1')\n",
    "# ratings contains 1 Million data, so it take some time\n",
    "print(movies, users, ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229626ae-416d-4b6a-89ae-5859869f0f4f",
   "metadata": {},
   "source": [
    " ### Preparing the Training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32784c10-ed28-4642-b961-3f05e46d6442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,        10,         3, 875693118],\n",
       "       [        1,        12,         5, 878542960],\n",
       "       [        1,        14,         5, 874965706],\n",
       "       ...,\n",
       "       [      459,       934,         3, 879563639],\n",
       "       [      460,        10,         3, 882912371],\n",
       "       [      462,       682,         5, 886365231]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The users movies rating in the ml 100k folder\n",
    "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\n",
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n",
    "\n",
    "# Converting the csv file to array\n",
    "training_set = np.array(training_set, dtype = 'int')\n",
    "test_set = np.array(test_set, dtype = 'int')\n",
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3bdbfc-85d3-4f97-ba89-0697be70b84b",
   "metadata": {},
   "source": [
    "### Gettting the number of users and movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9bc14d8-ef59-4c00-9408-a2f4aa28697d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n",
      "1682\n"
     ]
    }
   ],
   "source": [
    "nb_users = int(max(max(training_set[:,0]), max(training_set[:,0])))\n",
    "nb_movies = int(max(max(training_set[:,1]), max(training_set[:,1])))\n",
    "print(nb_users)\n",
    "print(nb_movies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9412b1d0-796d-46ba-9acf-fed74ae1ba2e",
   "metadata": {},
   "source": [
    "### Converting the data into an array with users in lines and movies in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82408019-73f7-42af-a053-31679f44ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert data into an required format\n",
    "\n",
    "# it is a list of lists\n",
    "# First list is 943 users, inside the each user it have another list\n",
    "# The second list have rating of all movies given by that particular user\n",
    "\n",
    "def convert(data):\n",
    "    new_data = []   # This is the final list of lists\n",
    "    \n",
    "    for id_users in range(1, nb_users+1):\n",
    "        id_movies = data[:, 1][data[:, 0] == id_users]    # We can mention the condition like this\n",
    "        id_ratings = data[:, 2][data[:, 0] == id_users]\n",
    "\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "\n",
    "        new_data.append(list(ratings))\n",
    "        \n",
    "    return new_data\n",
    "\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)\n",
    "# print(training_set)\n",
    "# print(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96013c59-0261-4251-858e-fd23ce4bf57d",
   "metadata": {},
   "source": [
    "### Converting the data into Torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b74c1d7b-53cb-44bd-a10a-35d536065b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 3., 4.,  ..., 0., 0., 0.],\n",
       "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 5., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The tensor converts all element into a single data type ( Here we convert into FLOAT )\n",
    "\n",
    "# The floattensor requires List of Lists only\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9db1cd-6ae8-47e2-8eed-40e72609858d",
   "metadata": {},
   "source": [
    "### Convertinig the ratings into binary ratings 1 (Liked) or 0 (Not liked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "615e1158-f0ef-4139-82dd-0d43c72016a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set[training_set == 0] = -1\n",
    "training_set[training_set == 1] = 0\n",
    "training_set[training_set == 2] = 0\n",
    "training_set[training_set >= 3] = 1\n",
    "\n",
    "test_set[test_set == 0] = -1\n",
    "test_set[test_set == 1] = 0\n",
    "test_set[test_set == 2] = 0\n",
    "test_set[test_set >= 3] = 1\n",
    "\n",
    "# Here we just convert into os and 1s, if not rated converted to -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c37314d-9778-4b9d-baef-b99bbbbea2b9",
   "metadata": {},
   "source": [
    "### Creating the architecture of the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e359078-d1d9-41c9-8d13-561ec473e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "    def __init__(self, nv, nh):   # num of visible and  hidden nodes\n",
    "        self.W = torch.randn(nh, nv)\n",
    "        self.a = torch.randn(1, nh) # Bias for hidden nodes\n",
    "        self.b = torch.randn(1, nv) # Bias for visible nodes\n",
    "\n",
    "    def sample_h(self, x):\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        activation = wx + self.a.expand_as(wx)\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "        \n",
    "    def sample_v(self, y):\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "        \n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.W += torch.mm(v0.t(), ph0).t() - torch.mm(vk.t(), phk).t()\n",
    "        self.b += torch.sum((v0 - vk), 0)\n",
    "        self.a += torch.sum((ph0 - phk), 0)\n",
    "        \n",
    "nv = len(training_set[0])\n",
    "nh = 100\n",
    "batch_size = 100\n",
    "rbm = RBM(nv, nh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e58931-8feb-4c71-93ff-b1c7129d708e",
   "metadata": {},
   "source": [
    "### Training the RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "531f969f-209a-4249-b708-b42d862cb6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(0.2448)\n",
      "epoch: 2 loss: tensor(0.2487)\n",
      "epoch: 3 loss: tensor(0.2461)\n",
      "epoch: 4 loss: tensor(0.2497)\n",
      "epoch: 5 loss: tensor(0.2459)\n",
      "epoch: 6 loss: tensor(0.2476)\n",
      "epoch: 7 loss: tensor(0.2444)\n",
      "epoch: 8 loss: tensor(0.2488)\n",
      "epoch: 9 loss: tensor(0.2454)\n",
      "epoch: 10 loss: tensor(0.2488)\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 10\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "        vk = training_set[id_user:id_user+batch_size]\n",
    "        v0 = training_set[id_user:id_user+batch_size]\n",
    "        ph0,_ = rbm.sample_h(v0)\n",
    "        for k in range(10):\n",
    "            _,hk = rbm.sample_h(vk)\n",
    "            _,vk = rbm.sample_v(hk)\n",
    "            vk[v0<0] = v0[v0<0]\n",
    "        phk,_ = rbm.sample_h(vk)\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n",
    "        s += 1.\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706f5c43-cd13-4418-ab80-b677a5c91148",
   "metadata": {},
   "source": [
    "### Testing the RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0dc76e3-6f93-4c1e-8e05-17fa3129b9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: tensor(0.2322)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    v = training_set[id_user:id_user+1]\n",
    "    vt = test_set[id_user:id_user+1]\n",
    "    if len(vt[vt>=0]) > 0:\n",
    "        _,h = rbm.sample_h(v)\n",
    "        _,v = rbm.sample_v(h)\n",
    "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870fbbee-70b9-42ee-8575-86300d6e127b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
